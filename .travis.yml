sudo: required
dist: bionic
language: python
cache: pip

python:
  - '3.6'
  - '3.7'
  - '3.8'

env:
  - PIP="pandas<1"
  - PIP="pandas>=1.0.3"
  - PIP="swifter"

before_install:
  - python -m pip install --upgrade pip setuptools wheel
  - pip install -r requirements.txt
  - pip install -r requirements_test.txt
  - pip install "$PIP"
  - export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
  - export SPARK_VERSION=2.4.7
  - export HADOOP_VERSION=2.7
  - export SPARK_DIRECTORY=../
  - export SPARK_HOME=../spark/
  - export ARROW_PRE_0_15_IPC_FORMAT=1
  - export SPARK_LOCAL_IP=127.0.0.1
  - make install-spark-ci

install:
  - python setup.py sdist bdist_wheel
  - twine check dist/*
  - make install

stages:
  - validation
  - test

script:
  - pytest -m "not spark_test" tests/
  - pytest -m spark_test tests/

jobs:
  include:
    - stage: validation
      name: "Linting"
      script:
        - make lint

#after_success:
#  - codecov -F $TEST
